{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/asoane34/TF_object_detection/blob/master/wheat_head_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF25_O0C_QTD"
   },
   "source": [
    "# Mounting Google Drive\n",
    "\n",
    "Before beginning the training, I am going to mount my Google Drive to this colab notebook. I have already [explored the data](https://github.com/asoane34/TF_object_detection/blob/master/00EDA.ipynb) and [prepared the TFRecord files](https://github.com/asoane34/TF_object_detection/blob/master/generate_tfrecords.py) and uploaded them to my Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jikGCiF_NhA"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "w5vfi8QQoXYf",
    "outputId": "836c1a77-6dcf-4dce-a1fc-f6ea945acada"
   },
   "outputs": [],
   "source": [
    "drive.mount(\"/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_AGskw3aolR7",
    "outputId": "2c7b057d-4f7d-4008-c568-fa29303bdb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection\n"
     ]
    }
   ],
   "source": [
    "%cd /gdrive/'My Drive'/object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQkkSv63_IQ1"
   },
   "source": [
    "# Specifying correct version of Tensorflow\n",
    "This is extremely important. The reason I migrated this project from Kaggle's environment over to Colab is that while it is possible to install Tensorflow 1.x (necessary for object detection API) in Kaggle's environment, the base image the notebooks are built off is not compatible with GPU training with Tensorflow 1.x. The Google Colab folks recommend NOT using !pip install to specify an earlier version, but rather using this tensorflow_version [magic command](https://colab.research.google.com/notebooks/tensorflow_version.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p9TBsoJ9owuc",
    "outputId": "a825ad6c-5b4d-45c2-96da-4fd943c9b9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TutETTx8-6m7",
    "outputId": "badb35ac-9692-4906-9335-8a003a85b0d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZ94e3k_EIfR"
   },
   "source": [
    "# Inspecting TFRecord files\n",
    "\n",
    "An issue I have run in to is encountering corruped TFRecord files. I'm not exactly sure how this happens, but judging from the number of open issues on TF's github it seems to be a frequent issue without any clear solution. So, before beginning the training process (and having the training process crash 4000 steps in, as it did the first time), I am going to quickly check the integrity of my files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gPbTJVI8Xyl"
   },
   "outputs": [],
   "source": [
    "def validate_dataset(filenames, reader_opts=None):\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for fname in filenames:\n",
    "        \n",
    "        print('validating ', fname)\n",
    "\n",
    "        record_iterator = tf.io.tf_record_iterator(path=fname, options=reader_opts)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            for _ in record_iterator:\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            \n",
    "            print('error in {} at record {}'.format(fname, i))\n",
    "            \n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "D9LVhFxNEyD1",
    "outputId": "9f9aa62d-a42e-47c4-e7c0-6c67a01a52e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating  ./global-wheat-detection/validation.tfrecord\n",
      "WARNING:tensorflow:From <ipython-input-6-aa888d7148d5>:9: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "validating  ./global-wheat-detection/train.tfrecord\n",
      "validating  ./global-wheat-detection/test_images.tfrecord\n"
     ]
    }
   ],
   "source": [
    "validate_dataset([\"./global-wheat-detection/validation.tfrecord\", \"./global-wheat-detection/train.tfrecord\",\n",
    "                  \"./global-wheat-detection/test_images.tfrecord\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXvd7M3rE_0N"
   },
   "source": [
    "Well, besides using a deprecated method, there do not appear to be any corrupt records. Hopefully this will hold true in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSMAGDxzBgKb"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Now, it is time to install the dependencies for the object detection API, clone in the object detection repo, and compile the [protobufs](https://developers.google.com/protocol-buffers). There's excellent documentation of the steps [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md), or you can just follow along. The dependencies (besides obviously TF 1.x) are:\n",
    "* Cython\n",
    "* contextlib2\n",
    "* pillow\n",
    "* lxml\n",
    "* jupyter\n",
    "* matplotlib\n",
    "* pycocotools: This one is from the COCO API, and can be accessed by cloning in the COCO API repo and copying the file from there.\n",
    "\n",
    "I'm sure most of these are already installed but I don't feel like guessing at which. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Q4scp2gDCdCE",
    "outputId": "1539df25-d558-49cd-c383-1d22838f3804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.17)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user Cython\n",
    "!pip install --user contextlib2\n",
    "!pip install --user pillow\n",
    "!pip install --user lxml\n",
    "!pip install --user matplotlib\n",
    "!pip install --user pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxEpAsT3CtZF"
   },
   "source": [
    "Well, didn't need to install any of these. Makes sense, they wrote it. Next, it is time to clone in the TF models repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "D_ZsWGBvC86a",
    "outputId": "ef2a101a-5789-4b73-a0e6-a2fd0e061000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 34705 (delta 1), reused 5 (delta 0), pack-reused 34694\u001b[K\n",
      "Receiving objects: 100% (34705/34705), 512.65 MiB | 14.43 MiB/s, done.\n",
      "Resolving deltas: 100% (22449/22449), done.\n",
      "Checking out files: 100% (2495/2495), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeT9gmphDuxt"
   },
   "source": [
    "Now, to compile the protobufs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TnWdLcB5DKZZ",
    "outputId": "4b6e807d-50d8-4d4f-b037-0f69dc6f819c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd models/research \n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIV6xbIDD_ir"
   },
   "source": [
    "The final step in this process before running the installation test script is to add the \"models/research\" and \"models/research/slim\" directories to path: PYTHONPATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jv626OjADf01",
    "outputId": "99d7e11e-5ba3-4fdd-bbd2-d33fcb17f46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tensorflow-1.15.2/python3.6:/env/python:/gdrive/My Drive/object_detection/models/research/slim:/gdrive/My Drive/object_detection/models/research'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':/gdrive/My Drive/object_detection/models/research/slim:/gdrive/My Drive/object_detection/models/research'\n",
    "\n",
    "os.environ['PYTHONPATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fl1e5pFHE_xP"
   },
   "source": [
    "Now, we are ready to run the __model_builder_test__ script. If this works, we have correctly installed the object detection API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "YNM-BbtcE3vo",
    "outputId": "234bb52f-03db-4114-d68b-1f42dba0b42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Running tests under Python 3.6.9: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 17 tests in 0.250s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec8rFR8vFZrB"
   },
   "source": [
    "Sweet, we are ready to roll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gb5RZj9oFkjq"
   },
   "source": [
    "# Configuring the Model for Training\n",
    "\n",
    "Rather than building and training a model from scratch, I have elected to apply transfer learning in this project and use a pretrained model from the [TF model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md). The model zoo features research models trained on the COCO dataset, the Kitti dataset, the Open Images dataset, the AVA v2.1 dataset, and the iNaturalist Species Detection Dataset. In this case, I have elected to use a Faster RCNN ResNet101 model trained on the iNaturalist Species Detection Dataset. Obviously we are not detecting species, but we are working with similar images so hopefully it will be a good selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EfYt_P2sFMRy",
    "outputId": "cd6b0841-ff85-49a4-955d-5c0be2bad1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research/object_detection\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/saved_model/saved_model.pb\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt.meta\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/pipeline.config\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/saved_model/\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt.index\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/saved_model/variables/\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt.data-00000-of-00001\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/checkpoint\n",
      "faster_rcnn_resnet101_fgvc_2018_07_19/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "%cd object_detection\n",
    "\n",
    "!wget -O faster_rcnn_resnet101_fgvc_2018_07_19.tar.gz http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19.tar.gz -q\n",
    "    \n",
    "!tar xvzf faster_rcnn_resnet101_fgvc_2018_07_19.tar.gz\n",
    "\n",
    "!rm faster_rcnn_resnet101_fgvc_2018_07_19.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "s0N1-txzGbJd",
    "outputId": "20c1ddc6-d9e2-497d-9a8f-25e91f36b102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19\n",
      "/gdrive/My Drive/object_detection/models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/export\n",
      "/gdrive/My Drive/object_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd faster_rcnn_resnet101_fgvc_2018_07_19\n",
    "\n",
    "!mkdir export\n",
    "\n",
    "%cd export\n",
    "\n",
    "!mkdir Servo\n",
    "\n",
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSSxiYDYHm7z"
   },
   "source": [
    "With the model loaded and the directory tree set up correctly, it is time to write the pipeline config file. This file specifies the parameters of the model as well as the paths to training and validation data and any potential data augmentations and evaluation metrics. The models in the TF zoo have [sample config files](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs), which are an excellent jumping off point. I will be using the [base config file](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config) for the model I have selected and tuning it to this particular project. First, to add a couple important directories to my path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6oXo67kHbpx"
   },
   "outputs": [],
   "source": [
    "os.environ['DATA_PATH'] = '/gdrive/My Drive/object_detection/global-wheat-detection'\n",
    "\n",
    "os.environ['MODEL_PATH'] = 'object_detection/faster_rcnn_resnet101_fgvc_2018_07_19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NKdddg1fK9au",
    "outputId": "facd8f8c-4055-4e87-d9e8-3e1b21a34b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19\n"
     ]
    }
   ],
   "source": [
    "%cd object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pbS-4aY95EL"
   },
   "source": [
    "## NOTE:  I have done several iterations of training, and thus in the .config file below, the \"fine tune checkpoint\" file has changed several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dq2SkE0EJXvO",
    "outputId": "04eaa897-3ab6-4164-f3b4-a360ec3e6c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting global_wheat_detection.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile global_wheat_detection.config\n",
    "model {\n",
    "  faster_rcnn {\n",
    "    num_classes: 1\n",
    "    image_resizer {\n",
    "      keep_aspect_ratio_resizer {\n",
    "        min_dimension: 600\n",
    "        max_dimension: 1024\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'faster_rcnn_resnet101'\n",
    "      first_stage_features_stride: 16\n",
    "    }\n",
    "    first_stage_anchor_generator {\n",
    "      grid_anchor_generator {\n",
    "        scales: [0.25, 0.5, 1.0, 2.0]\n",
    "        aspect_ratios: [0.5, 1.0, 2.0]\n",
    "        height_stride: 16\n",
    "        width_stride: 16\n",
    "      }\n",
    "    }\n",
    "    first_stage_box_predictor_conv_hyperparams {\n",
    "      op: CONV\n",
    "      regularizer {\n",
    "        l2_regularizer {\n",
    "          weight: 0.0\n",
    "        }\n",
    "      }\n",
    "      initializer {\n",
    "        truncated_normal_initializer {\n",
    "          stddev: 0.01\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    first_stage_nms_score_threshold: 0.0\n",
    "    first_stage_nms_iou_threshold: 0.7\n",
    "    first_stage_max_proposals: 300\n",
    "    first_stage_localization_loss_weight: 2.0\n",
    "    first_stage_objectness_loss_weight: 1.0\n",
    "    initial_crop_size: 14\n",
    "    maxpool_kernel_size: 2\n",
    "    maxpool_stride: 2\n",
    "    second_stage_batch_size: 32\n",
    "    second_stage_box_predictor {\n",
    "      mask_rcnn_box_predictor {\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 1.0\n",
    "        fc_hyperparams {\n",
    "          op: FC\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 0.0\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            variance_scaling_initializer {\n",
    "              factor: 1.0\n",
    "              uniform: true\n",
    "              mode: FAN_AVG\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    second_stage_post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 0.0\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 116\n",
    "        max_total_detections: 116\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "    second_stage_localization_loss_weight: 2.0\n",
    "    second_stage_classification_loss_weight: 1.0\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 1\n",
    "  num_steps: 4000000\n",
    "  optimizer {\n",
    "    momentum_optimizer: {\n",
    "      learning_rate: {\n",
    "        manual_step_learning_rate {\n",
    "          initial_learning_rate: 0.0003\n",
    "          schedule {\n",
    "            step: 61000\n",
    "            learning_rate: .00003\n",
    "          }\n",
    "          schedule {\n",
    "            step: 100000\n",
    "            learning_rate: .000003\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "    }\n",
    "    use_moving_average: false\n",
    "  }\n",
    "  gradient_clipping_by_norm: 10.0\n",
    "  fine_tune_checkpoint: \"/gdrive/My Drive/object_detection/models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt-60000\"\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "    \n",
    "train_input_reader: {\n",
    "  label_map_path: \"/gdrive/My Drive/object_detection/global-wheat-detection/label_map.pbtxt\"\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/gdrive/My Drive/object_detection/global-wheat-detection/train.tfrecord\"\n",
    "  }\n",
    "}\n",
    "    \n",
    "eval_config: {\n",
    "  metrics_set: \"pascal_voc_detection_metrics\"\n",
    "  use_moving_averages: false\n",
    "  num_examples: 675\n",
    "}\n",
    "    \n",
    "eval_input_reader: {\n",
    "  label_map_path: \"/gdrive/My Drive/object_detection/global-wheat-detection/label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/gdrive/My Drive/object_detection/global-wheat-detection/validation.tfrecord\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zO39NdpYMWh7",
    "outputId": "a0e5a6c5-3bb6-40e4-b03e-ca45848f474a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0cf4OE6cjDt"
   },
   "source": [
    "Quickly test to make sure the GPU is connected, this will take a very long time without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7nxJuT_tcR8b",
    "outputId": "cfa4f890-c386-4950-a22c-4d8e56b8e4f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0d9KCrMHeIxx"
   },
   "source": [
    "# Model Training\n",
    "\n",
    "Now with the modeling pipeline configured and everything installed, it is time to train the model. Colab allows us 12 hours of GPU usage and that will be more than enough for the first round of training. \n",
    "\n",
    "Because my Google Drive is synced locally, I am going connect to the Tensorboard locally, but it your GDrive is not synced locally, this is also possible using Ngrok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "gB3ZliQPf2xK",
    "outputId": "ac0c1f35-9e6c-436a-ba2e-e81e4d810b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-12 22:57:22--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 52.2.129.46, 54.85.41.146, 52.6.123.150, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|52.2.129.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13773305 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.13M  5.97MB/s    in 2.2s    \n",
      "\n",
      "2020-05-12 22:57:25 (5.97 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NENByVQDgNq4",
    "outputId": "e88660d8-fb98-428b-8ee5-520ce7646138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://e7a1eaa2.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(\"object_detection/faster_rcnn_resnet101_fgvc_2018_07_19\")\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "#The link to tensorboard.\n",
    "#works after the training starts.\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tqTGP_qShnHr",
    "outputId": "9d5c8c4d-f339-47e7-e51e-55343ca19888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIlIVeVhj8ue"
   },
   "outputs": [],
   "source": [
    "!rm object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgrQIWtMgoPx"
   },
   "outputs": [],
   "source": [
    "!python object_detection/model_main.py \\\n",
    "    --pipeline_config_path=object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/global_wheat_detection.config \\\n",
    "    --model_dir=object_detection/faster_rcnn_resnet101_fgvc_2018_07_19 \\\n",
    "    --num_train_steps=120000 \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --alsologtostderr=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hp10EPoQtORH"
   },
   "source": [
    "# Exporting Trained Model for Inference\n",
    "\n",
    "With the model tuned to the new dataset, it is time to export the last trained checkpoint and export the model for inference. This can be done by identifying the last model checkpoint, and then running the __export_inference_graph__ script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgxEl2vBrNLs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "ckpts = [f for f in os.listdir('object_detection/faster_rcnn_resnet101_fgvc_2018_07_19') \\\n",
    "       if 'model.ckpt-' in f and '.meta' in f]\n",
    "\n",
    "ckpt_steps = np.array([int(re.findall('\\d+', f)[0]) for f in ckpts])\n",
    "\n",
    "last_model = ckpts[ckpt_steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join('object_detection/faster_rcnn_resnet101_fgvc_2018_07_19', last_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uqq_9BpjwbMW",
    "outputId": "c37767e0-b0b8-4635-95f5-464bade31822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt-120000'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WaVSacGPuFr6"
   },
   "source": [
    "First, I will create a destination to write the frozen inference graph to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06Xh-whXslma"
   },
   "outputs": [],
   "source": [
    "output_dir = \"object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model120000/\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRTr7B8RtISV"
   },
   "outputs": [],
   "source": [
    "!python object_detection/export_inference_graph.py \\\n",
    "   --input_type=image_tensor \\\n",
    "   --pipeline_config_path object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/global_wheat_detection.config \\\n",
    "   --output_directory object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model120000/ \\\n",
    "   --trained_checkpoint_prefix object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/model.ckpt-120000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Dru_LaLqG4H"
   },
   "source": [
    "Next, there is a script to run inference with the trained model on test images [here](https://github.com/tensorflow/models/blob/master/research/object_detection/inference/infer_detections.py). The command below executes that command and returns a tfrecord with the proposed detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfK-gY_YoF2_"
   },
   "outputs": [],
   "source": [
    "!python object_detection/inference/infer_detections.py \\\n",
    "  --input_tfrecord_paths=/gdrive/'My Drive'/object_detection/global-wheat-detection/test_images.tfrecord \\\n",
    "  --output_tfrecord_path=/gdrive/'My Drive'/object_detection/global-wheat-detection/inferences120000.tfrecord \\\n",
    "  --inference_graph=object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model120000/frozen_inference_graph.pb \\\n",
    "  --discard_image_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGdQsC-hqYyL"
   },
   "source": [
    "I also am going to save the model locally to use for inference on my Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nTIP6UT-zhiW",
    "outputId": "64e4c348-0e7b-4abe-bd6f-d1a215c68c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/object_detection\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "AoSTrkzbz0gR",
    "outputId": "26cbdf10-e7cb-4296-87ec-8b7c0ff493b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/model.ckpt.data-00000-of-00001\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/model.ckpt.index\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/checkpoint\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/model.ckpt.meta\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/frozen_inference_graph.pb\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/saved_model/\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/saved_model/variables/\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/saved_model/saved_model.pb\n",
      "models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf global-wheat-detection/trained_model.tar.gz models/research/object_detection/faster_rcnn_resnet101_fgvc_2018_07_19/trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "250M1bMixPKj"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('global-wheat-detection/trained_model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8P6zYv-zMw5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPybh/Zp+LuLnzjSjsqa+1J",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "wheat-head-detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
